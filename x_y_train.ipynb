{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ab737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os  \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import ast \n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d2aa2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_vs_player_stats=pd.read_csv('dt/player_vs_player_stats.csv') \n",
    "player_stats_with_date_venue=pd.read_csv('dt/odi_player_stats_with_date_venue.csv') \n",
    "all_matches_player=pd.read_csv('dt/matches_all_players.csv') \n",
    "fantasy_points=pd.read_csv('fantasy_points_data.csv') \n",
    "venues_with_dates_with_locations_with_weather=pd.read_csv('dt/odis_venues_with_dates_with_locations_with_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93b9684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_venue_stats(df, player_name, venue, date, delta): \n",
    "    import numpy as np \n",
    "    import pandas as pd \n",
    "    from datetime import timedelta\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    end_date = pd.to_datetime(date)\n",
    "    start_date = end_date - timedelta(days=delta)\n",
    "    filtered_df = df[\n",
    "        (df['player_name'] == player_name) & \n",
    "        (df['Venue'] == venue) & \n",
    "        (df['Date'] >= start_date) & \n",
    "        (df['Date'] < end_date)\n",
    "    ]\n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame([{\n",
    "            'runs_scored': 0,\n",
    "            'balls_faced': 0,\n",
    "            'wickets_taken': 0,\n",
    "            'runs_given': 0,\n",
    "            'balls_thrown': 0,\n",
    "            'boundaries_scored': 0,\n",
    "            'boundaries_given': 0,\n",
    "            'number_of_dismissals': 0,\n",
    "            'strike_rate': 0,\n",
    "            'economy': 0,\n",
    "            'batting_average': 0,\n",
    "            'fantasy_points': 0,\n",
    "            'number_of_matches_played': 0\n",
    "        }])\n",
    "    aggregated_stats = {\n",
    "        'Date': date,\n",
    "        'Venue': venue,\n",
    "        'player_Id': filtered_df['player_Id'].iloc[0],  # Assuming player_Id is unique for a player\n",
    "        'player_name': player_name,\n",
    "        'runs_scored': filtered_df['runs_scored'].sum(),\n",
    "        'balls_faced': filtered_df['balls_faced'].sum(),\n",
    "        'wickets_taken': filtered_df['wickets_taken'].sum(),\n",
    "        'runs_given': filtered_df['runs_given'].sum(),\n",
    "        'balls_thrown': filtered_df['balls_thrown'].sum(),\n",
    "        'boundaries_scored': filtered_df['boundaries_scored'].sum(),\n",
    "        'boundaries_given': filtered_df['boundaries_given'].sum(),\n",
    "        'number_of_dismissals': filtered_df['number_of_dismissals'].sum(),\n",
    "        'strike_rate': (filtered_df['runs_scored'].sum() / (filtered_df['balls_faced'].sum() if filtered_df['balls_faced'].sum() != 0 else 1)),\n",
    "        'economy': ((filtered_df['runs_given'].sum() * 6) / (filtered_df['balls_thrown'].sum() if filtered_df['balls_thrown'].sum() != 0 else 1)),\n",
    "        'batting_average': (filtered_df['runs_scored'].sum() / (filtered_df['number_of_dismissals'].sum() if filtered_df['number_of_dismissals'].sum() != 0 else 1)),\n",
    "        'fantasy_points': filtered_df['fantasy_points'].sum(),\n",
    "        'number_of_matches_played': filtered_df.shape[0]  # Number of matches played in the interval\n",
    "    } \n",
    "    a=pd.DataFrame([aggregated_stats]) \n",
    "    a=a.drop(['Date','Venue','player_Id','player_name'],axis=1)\n",
    "    return a \n",
    "def get_player_vs_player_stats_ordered(df, player1_name, player2_names, date, delta): \n",
    "    import numpy as np \n",
    "    import pandas as pd \n",
    "    from datetime import timedelta\n",
    "    df['match_date'] = pd.to_datetime(df['match_date'])\n",
    "    end_date = pd.to_datetime(date)\n",
    "    start_date = end_date - timedelta(days=delta)\n",
    "    filtered_df = df[\n",
    "        (df['match_date'] >= start_date) & \n",
    "        (df['match_date'] < end_date)\n",
    "    ]\n",
    "    direct_matches = filtered_df[\n",
    "        (filtered_df['player1_name'] == player1_name) & \n",
    "        (filtered_df['player2_name'].isin(player2_names))\n",
    "    ]\n",
    "    \n",
    "    reverse_matches = filtered_df[\n",
    "        (filtered_df['player2_name'] == player1_name) & \n",
    "        (filtered_df['player1_name'].isin(player2_names))\n",
    "    ]\n",
    "    reverse_matches = reverse_matches.rename(columns={\n",
    "        'player1_id': 'player2_id', 'player1_name': 'player2_name',\n",
    "        'player2_id': 'player1_id', 'player2_name': 'player1_name',\n",
    "        'runs_b1_b2': 'runs_b2_b1', 'balls_b1_b2': 'balls_b2_b1',\n",
    "        'boundaries_b1_b2': 'boundaries_b2_b1', 'dismissals_b1_b2': 'dismissals_b2_b1',\n",
    "        'runs_b2_b1': 'runs_b1_b2', 'balls_b2_b1': 'balls_b1_b2',\n",
    "        'boundaries_b2_b1': 'boundaries_b1_b2', 'dismissals_b2_b1': 'dismissals_b1_b2',\n",
    "        'strike_rate_b1_b2': 'strike_rate_b2_b1', 'strike_rate_b2_b1': 'strike_rate_b1_b2',\n",
    "        'economy_b1_b2': 'economy_b2_b1', 'economy_b2_b1': 'economy_b1_b2',\n",
    "        'fantasy_point_p1_p2': 'fantasy_point_p2_p1', 'fantasy_point_p2_p1': 'fantasy_point_p1_p2'\n",
    "    })\n",
    "    combined_df = pd.concat([direct_matches, reverse_matches], ignore_index=True)\n",
    "    aggregated_df = combined_df.groupby(['player1_id', 'player1_name', 'player2_id', 'player2_name']).agg({\n",
    "    'runs_b1_b2': 'sum',\n",
    "    'balls_b1_b2': 'sum',\n",
    "    'boundaries_b1_b2': 'sum',\n",
    "    'dismissals_b1_b2': 'sum',\n",
    "    'fantasy_point_p1_p2': 'sum',\n",
    "    'match_date': 'count' \n",
    "          }).reset_index()\n",
    "    aggregated_df['strike_rate_b1_b2'] = aggregated_df['runs_b1_b2'] / aggregated_df['balls_b1_b2'].replace(0, 1)\n",
    "    aggregated_df['economy_b1_b2'] = (aggregated_df['runs_b1_b2']*6) / (aggregated_df['balls_b1_b2'] ).replace(0, 1)\n",
    "    aggregated_df.rename(columns={'match_date': 'number_of_matches_played'}, inplace=True)\n",
    "    result_rows = []\n",
    "    for player2_name in player2_names:\n",
    "        row = aggregated_df[aggregated_df['player2_name'] == player2_name]\n",
    "        if not row.empty: \n",
    "            row=row.drop(['player1_id','player1_name','player2_id','player2_name'],axis=1)\n",
    "            result_rows.append(row.iloc[0].to_dict())  # Add the existing row\n",
    "        else:\n",
    "            result_rows.append({\n",
    "                'runs_b1_b2': 0,\n",
    "                'balls_b1_b2': 0,\n",
    "                'boundaries_b1_b2': 0,\n",
    "                'dismissals_b1_b2': 0,\n",
    "                'strike_rate_b1_b2': 0,\n",
    "                'economy_b1_b2': 0,\n",
    "                'fantasy_point_p1_p2': 0,\n",
    "                'number_of_matches_played': 0\n",
    "            })\n",
    "    \n",
    "    # Convert result_rows to a DataFrame\n",
    "    result_df = pd.DataFrame(result_rows) \n",
    "    return result_df \n",
    "def get_player_matchwise_stats(df, player, date, delta): \n",
    "    import numpy as np \n",
    "    import pandas as pd \n",
    "    from datetime import timedelta\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    end_date = pd.to_datetime(date)\n",
    "    start_date = end_date - timedelta(days=delta)\n",
    "    filtered_df = df[\n",
    "        (df['Player'] == player) &\n",
    "        (df['Date'] >= start_date) &\n",
    "        (df['Date'] < end_date)\n",
    "    ]\n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame([{\n",
    "            'EWMA Fantasy Points': 0,\n",
    "            'total_points': 0,\n",
    "            'Runs': 0,\n",
    "            'Wickets': 0,\n",
    "            'Balls_Faced': 0,\n",
    "            'Strike_Rate': 0,\n",
    "            'matches_played': 0, \n",
    "            'Runs_Given': 0,  \n",
    "            'Balls_Thrown': 0,  \n",
    "            'Boundaries_Scored': 0,  \n",
    "            'Boundaries_Given': 0,  \n",
    "            'Number_of_Dismissals': 0,  \n",
    "            'Economy': 0, \n",
    "            'Batting_Average': 0\n",
    "        }])\n",
    "    filtered_df = filtered_df.sort_values(by='Date')\n",
    "    filtered_df['EWMA Fantasy Points'] = filtered_df['EWMA Fantasy Points']\n",
    "    filtered_df['EWMA Fantasy Points'].fillna(0, inplace=True)\n",
    "    aggregated_stats = {\n",
    "        'EWMA Fantasy Points': filtered_df['EWMA Fantasy Points'].iloc[-1],  \n",
    "        'total_points': filtered_df['total_points'].sum(),\n",
    "        'Runs': filtered_df['Runs_Scored'].sum(),\n",
    "        'Wickets': filtered_df['Wickets_Taken'].sum(),\n",
    "        'Balls_Faced': filtered_df['Balls_Faced'].sum(),\n",
    "        'Strike_Rate': (filtered_df['Runs_Scored'].sum() / (filtered_df['Balls_Faced'].sum() if filtered_df['Balls_Faced'].sum() != 0 else 1)),\n",
    "        'matches_played': len(filtered_df), \n",
    "        'Runs_Given': filtered_df['Runs_Given'].sum(), \n",
    "        'Balls_Thrown': filtered_df['Balls_Thrown'].sum(), \n",
    "        'Boundaries_Scored': filtered_df['Boundaries_Scored'].sum(), \n",
    "        'Boundaries_Given': filtered_df['Boundaries_Given'].sum(), \n",
    "        'Number_of_Dismissals': filtered_df['Number_of_Dismissals'].sum(),  \n",
    "        'Economy':((filtered_df['Runs_Given'].sum()*6) / (filtered_df['Balls_Thrown'].sum() if filtered_df['Balls_Thrown'].sum() != 0 else 1)),\n",
    "        'Batting_Average': (filtered_df['Runs_Scored'].sum() / (filtered_df['Number_of_Dismissals'].sum() if filtered_df['Number_of_Dismissals'].sum() != 0 else 1)),\n",
    "    }\n",
    "    a = pd.DataFrame([aggregated_stats]) \n",
    "    return a \n",
    "counter=0\n",
    "def stack_and_pad_dataframes(df1, df2, df3, df4,x_train=x_train):\n",
    "    global counter\n",
    "    current_rows, num_columns = df1.shape\n",
    "    required_rows=12\n",
    "    if current_rows < required_rows:\n",
    "        missing_rows = required_rows - current_rows\n",
    "        zero_padding = pd.DataFrame(\n",
    "            0, \n",
    "            index=range(missing_rows), \n",
    "            columns=df1.columns\n",
    "        )\n",
    "        padded_df = pd.concat([df1, zero_padding], ignore_index=True)\n",
    "    elif current_rows > required_rows:\n",
    "        padded_df = df1.iloc[:required_rows, :]\n",
    "    else:\n",
    "        padded_df = df1\n",
    "    flattened_array = padded_df.to_numpy().flatten()\n",
    "    reshaped_array = flattened_array.reshape(-1, 1)\n",
    "    flattened_array2 = df2.to_numpy().flatten()\n",
    "    flattened_array3 = df3.to_numpy().flatten()\n",
    "    flattened_array4 = df4.to_numpy().flatten()\n",
    "    stacked_array = np.concatenate([ reshaped_array.reshape(1, -1), \n",
    "                                    flattened_array2.reshape(1, -1),\n",
    "                                    flattened_array3.reshape(1, -1),\n",
    "                                    flattened_array4.reshape(1, -1)], axis=1)\n",
    "    final_array = stacked_array.reshape(1, -1)\n",
    "    x_train[counter] = final_array\n",
    "    counter += 1 \n",
    "def get_fantasy_points(df, player_name, match_date):\n",
    "    result = df[(df['Player Name'] == player_name) & (df['Match Date'] == match_date)]\n",
    "    if not result.empty:\n",
    "        return result['Fantasy Points'].values[0]\n",
    "    else:\n",
    "        return 0 \n",
    "def get_weather_data(dataframe, date, venue): \n",
    "    import numpy as np \n",
    "    import pandas as pd \n",
    "    from datetime import timedelta\n",
    "    match = dataframe[(dataframe['start_date'] == date) & (dataframe['venue'] == venue)]\n",
    "    if not match.empty:\n",
    "        match=match.drop(['start_date','venue','latitude','longitude'],axis=1)\n",
    "        return match\n",
    "    else:\n",
    "        zero_row = pd.DataFrame([{\n",
    "            'temperature': 0,\n",
    "            'precipitation': 0,\n",
    "            'wind_speed': 0\n",
    "        }])\n",
    "        return zero_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b81694bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.zeros((70000,126)) \n",
    "y_train=np.zeros(70000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8da02ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1='dt/csv1'  \n",
    "data2='dt/csv2' \n",
    "data3='dt/csv3' \n",
    "data_1=os.listdir(data1) \n",
    "data_2=os.listdir(data2) \n",
    "data_3=os.listdir(data3)  \n",
    "i=0\n",
    "for data in data_1: \n",
    "    path2=os.path.join(data1,data) \n",
    "    data=pd.read_csv(path2)   \n",
    "    team1_players=data['team1_players'].apply(ast.literal_eval)[0]\n",
    "    team2_players=data['team2_players'].apply(ast.literal_eval)[0] \n",
    "    date=data['date'][0] \n",
    "    venue=data['venue'][0]  \n",
    "    for player in team1_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team2_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e   \n",
    "        i=i+1 \n",
    "    for player in team2_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team1_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e  \n",
    "        i=i+1 \n",
    "for data in data_2: \n",
    "    path2=os.path.join(data2,data) \n",
    "    data=pd.read_csv(path2)   \n",
    "    team1_players=data['team1_players'].apply(ast.literal_eval)[0]\n",
    "    team2_players=data['team2_players'].apply(ast.literal_eval)[0] \n",
    "    date=data['date'][0] \n",
    "    venue=data['venue'][0]  \n",
    "    for player in team1_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team2_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e   \n",
    "        i=i+1 \n",
    "    for player in team2_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team1_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e  \n",
    "        i=i+1 \n",
    "for data in data_3: \n",
    "    path2=os.path.join(data3,data) \n",
    "    data=pd.read_csv(path2)   \n",
    "    team1_players=data['team1_players'].apply(ast.literal_eval)[0]\n",
    "    team2_players=data['team2_players'].apply(ast.literal_eval)[0] \n",
    "    date=data['date'][0] \n",
    "    venue=data['venue'][0]  \n",
    "    for player in team1_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team2_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e   \n",
    "        i=i+1 \n",
    "    for player in team2_players:  \n",
    "        a=get_player_venue_stats(player_stats_with_date_venue,player,venue,date,3000) \n",
    "        b=get_player_matchwise_stats(all_matches_player,player,date,180) \n",
    "        c=get_player_vs_player_stats_ordered(player_vs_player_stats,player,team1_players,date,800) \n",
    "        d=get_weather_data(venues_with_dates_with_locations_with_weather,date,venue) \n",
    "        stack_and_pad_dataframes(c,a,b,d) \n",
    "        e=get_fantasy_points(fantasy_points,player,date) \n",
    "        y_train[i]=e  \n",
    "        i=i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24c3bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2=x_train[:52000,:] \n",
    "y_train2=y_train[:52000]  \n",
    "x_train2=pd.DataFrame(x_train2) \n",
    "y_train2=pd.DataFrame(y_train2) \n",
    "x_train2.to_csv('x_train.csv',index=False) \n",
    "y_train2.to_csv('y_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e8007c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7., 85., 86., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56b8f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open(\"get_player_venue_stats.pkl\", \"wb\") as f:\n",
    "    dill.dump(get_player_venue_stats, f) \n",
    "with open(\"get_player_matchwise_stats.pkl\", \"wb\") as f:\n",
    "    dill.dump(get_player_matchwise_stats, f) \n",
    "with open(\"get_player_vs_player_stats_ordered.pkl\", \"wb\") as f:\n",
    "    dill.dump(get_player_vs_player_stats_ordered, f) \n",
    "with open(\"get_weather_data.pkl\", \"wb\") as f:\n",
    "    dill.dump(get_weather_data, f) \n",
    "with open(\"stack_and_pad_dataframes.pkl\", \"wb\") as f:\n",
    "    dill.dump(stack_and_pad_dataframes, f) \n",
    "with open(\"get_fantasy_points.pkl\", \"wb\") as f:\n",
    "    dill.dump(get_fantasy_points, f)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
